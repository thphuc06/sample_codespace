import pandas as pd
import geopandas as gpd
import requests
import time
import os
import osmnx as ox
import re

def geocode_geoapify(query_text):
    url = "https://api.geoapify.com/v1/geocode/search"
    
    print(query_text)

    params = {
        'text': query_text,
        'apiKey': 'f1f9fa86b35b4087b305c6bb4d6250be',
        'limit': 1,
        'format': 'json'  
    }

    try:
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()

        if data and data.get('results') and len(data['results']) > 0:
            best_result = data['results'][0]
            
            lon = best_result['lon']
            lat = best_result['lat']
            
            confidence = best_result['rank']['confidence']
            print(f"{lat} - {lon}")
            return pd.Series({'lat' :  lat, 'lon':lon})
        else:
            print("nah")
    except Exception as e:
        print(f"Geoapify error: {e}")

    return pd.Series({'lat':None, 'lon':None})


def geocode_batch(df, name_column='name', address_column='address', dist = '', city = ''):
    df['address'] = df['address'] + f', {dist}, {city}' 
    df[['lat', 'lon']] =  df.apply(lambda row: geocode_geoapify(f"{row[name_column]}, {row['address']}"), axis=1)

    prob = df['lat'].notna().sum() / len(df) * 100
    print(f"success: {prob}")
    return df


# ==================== STEP 2: CLEAN DATA ====================
def alter_count(cnt):
    # print(type(cnt))
    try:
        cnt = float(cnt)
        if cnt < 0.0:
            return -cnt
        else:
            return cnt
    except ValueError:
        #string -> need to parse
        pattern = r'\(?([\d,.]+)([A-Z\sa-z]*)\)?'
        cnt = cnt.replace('"', '').strip()
        # print(cnt)
        match = re.search(pattern, cnt)
        if match:
            try:
                num = match.group(1)
                num = float(num.replace(',','.'))
                char = match.group(2).strip()
                # print(char)
                if char and (char.upper() == 'N' or char.upper() == 'K'):
                    return num * 1000
                else:
                    return num
            except ValueError as e:
                return
        else:
            print('check again pattern')
    return 0

def alter_rating(rating):
    
    if isinstance(rating, (int, float)):
        if pd.isna(rating): 
            return 0.0     
        return float(rating)

    if isinstance(rating, str):
        try:
            clean_str = rating.replace(',', '.').replace('"', '').strip()
            
            if not clean_str:
                return 0.0

            return float(clean_str)
        
        except ValueError:
            return 0.0
        
    return 0.0

def clean_data(df):
    initial_count = len(df)

    # 1. Remove null lat/lon (geocode th·∫•t b·∫°i)
    df = df.dropna(subset=['lat', 'lon'])
    print(f"  Removed {initial_count - len(df)} rows (Geocode failed)")

    # 3. Remove duplicates (based on lat/lon)
    df = df.drop_duplicates(subset=['lat', 'lon'])
    print(f"  Removed {initial_count - len(df)} rows (Duplicates)")

    df.fillna(value={'comment': 'kh√¥ng c√≥ ƒë√°nh gi√°'}, inplace=True)    
    df['comment'] = df['comment'].str.strip(' "')
    df['type'] = df['type'].str.replace('¬∑ ', '').str.strip()

    df['count'] = df.apply(lambda row: alter_count(row['count']), axis = 1)

    df['rating'] = df.apply(lambda row: alter_rating(row['rating']), axis = 1)

    # df.drop('category', axis = 1, inplace = True)

    print(f"\n  Initial rows: {initial_count}")
    print(f"  After cleaning: {len(df)}")
    print(f"  Total removed: {initial_count - len(df)} rows")

    return df


# ==================== STEP 3: SPATIAL FILTERING ====================
def filter_by_boundary(df, district_query):
    print(f" Query: {district_query}")
    try:
        gdf_boundary = ox.geocode_to_gdf(district_query)
        print(f"   Successfully downloaded boundary")
    except Exception as e:
        print(f"   Error downloading from OSM: {e}")
        raise
        
    print(f" Creating GeoDataFrame from {len(df)} points...")
    gdf_points = gpd.GeoDataFrame(
        df,
        geometry=gpd.points_from_xy(df.lon, df.lat),
        crs="epsg:4326"
    )

    # L∆∞u t√™n c√°c c·ªôt g·ªëc (kh√¥ng bao g·ªìm geometry)
    original_columns = [col for col in gdf_points.columns if col != 'geometry']
    gdf_boundary = gpd.GeoDataFrame(gdf_boundary.geometry)
    print(f"   Filtering points within boundary...")
    gdf_inside = gpd.sjoin(
        gdf_points,
        gdf_boundary,
        how="inner",
        predicate="within"
    )

    print(f"   üìä Results:")
    print(f"     Total points (pre-filter): {len(gdf_points)}")
    print(f"     ‚úÖ Inside boundary: {len(gdf_inside)}")
    print(f"     ‚ùå Outside boundary (removed): {len(gdf_points) - len(gdf_inside)}")

    # K·∫øt qu·∫£ tr·∫£ v·ªÅ l√† m·ªôt GeoDataFrame
    return gdf_inside[df.columns.to_list() + ['geometry']] 

# ==================== MAIN PIPELINE ====================

def run_pipeline(
    input_file,
    district,
    city,
    output_file,
    name_column='name',
    address_column='address'
):
    """
    Ch·∫°y to√†n b·ªô pipeline:
    1. Load Excel/CSV
    2. Geocode (Geoapify)
    3. Clean
    4. Filter by boundary (OSMnx)
    5. Save to new CSV
    """
    print("="*60)
    print("üöÄ STARTING DATA PIPELINE (Geoapify -> CSV)")
    print("="*60)

    # Step 0: Load data
    print(f"\nüìÇ STEP 0: LOADING DATA from {input_file}...")
    if input_file.endswith('.xlsx'):
        df = pd.read_excel(input_file)
    else:
        df = pd.read_csv(input_file, encoding='utf-8')

    print(f"  Loaded {len(df)} rows")

    # Step 1: Geocode
    df = geocode_batch(df, name_column=name_column, address_column=address_column, dist = district, city = city)

    # Step 2: Clean
    df = clean_data(df)
    
    # Ki·ªÉm tra n·∫øu kh√¥ng c√≤n d·ªØ li·ªáu sau khi clean
    if df.empty:
        print("\nNo data left after cleaning. Exiting.")
        return df

    # Step 3: Spatial filter
    df = filter_by_boundary(df, district_query=f'{district}, Th√†nh ph·ªë H·ªì Ch√≠ Minh, Vi·ªát Nam')

    # Step 4: Save to CSV
    if output_file:
        df.to_csv(output_file, encoding='utf-8', index=False)
        print(f"\nSaved processed data to: {output_file}")
    else:
        print("\nNo output_file specified. Skipping save.")

    print("\n" + "="*60)
    print("‚úÖ PIPELINE COMPLETE!")
    print("="*60)

    return df


# ==================== EXAMPLE USAGE ====================

if __name__ == "__main__":

    # ƒê·∫£m b·∫£o b·∫°n c√≥ file .env v·ªõi GEOAPIFY_API_KEY

    result_gdf = run_pipeline(
        input_file="full_q1.csv",      # File input c·ªßa b·∫°n
        name_column="name",         # T√™n c·ªôt ch·ª©a t√™n ƒë·ªãa ƒëi·ªÉm
        address_column="address",   # T√™n c·ªôt ch·ª©a ƒë·ªãa ch·ªâ
        district="Qu·∫≠n 1",
        city = "Th√†nh ph·ªë H·ªì Ch√≠ Minh",
        output_file="quan1_filtered_full.csv"  # File output
    )

    print("\n" + "="*60)
    print("üìä FINAL RESULTS PREVIEW")
    print("="*60)
    if not result_gdf.empty:
        print(f"Total locations: {len(result_gdf)}")
        print(f"Output file: quan1_filtered_geoapify.csv")
        print(f"\nPreview:")
        print(result_gdf.head())
    else:
        print("No locations found matching all criteria.")